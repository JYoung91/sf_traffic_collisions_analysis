---
title: "traffic_collisions_sf_machine_learning"
author: "Jeremie Young"
date: "January 5, 2019"
output: html_document
---

In my problem, I am hoping to predict the outcomes of "Collision Severity", which is defined by 5 features below.

The features are ordinal from least to most severe:
-Property Damage
-Injury (Minor)
-Injury (Moderate)
-Injury (Severe)
-Fatality

The specific model I will be using is a multi-nomial logistic regression to make predictions for the multiple outcomes. 

However, it is important to understand binary logistic regression model in which a multi-nomial regression is derived from. This particular model predicts a response variable on a binary level, either "TRUE or FALSE", "this or that", and in this context, "fatal or non-fatal", in relation to explanatory variable(s) that are used to determine the outcome.

This feature engineering of the response variable would clearly consolidate 4 non-fatal features into one, while fatalities remain untouched:

-non-fatal <- -Injury (severe)
              -Injury (other visible)
              -Injury (complaint of pain)
              -PDO (property damage only)
-fatal 

Explanatory variables are responsible in serving as predictors of the "fatal and non-fatal" outcome. We can determine a singular best fit predictor based on its coefficients as statistically significant to our problem. 

Our explanatory variables are all discrete variables, meaning that there are a finite amount of values:
-PCF Violation (Primary Collision Factors)
-Light Conditions
-Road Surface
-Pedestrian Action
-Alcohol Involved
-Collision Type

---------------

Below, I will be performing a binary logistic regression using a single explanatory variable to predict the outcome.

Import cleaned .csv with new variable "fatal"

```{r}
ml.colsev <- read.csv("C:/Users/jeremiey/Google Drive/Data Science/Springboard Intro to Data Science/Capstone/CollisionRecordsCleanedv3.csv")
head(ml.colsev)
```

Perform logistic regression model with each predictor of Fatal to determine coefficients. Also include cross table to observe distribution.

```{r}
xtabs(~ Fatal + Collision_Type, data = ml.colsev)
glm1 <- glm(Fatal ~ Collision_Type, data = ml.colsev, family = "binomial")
summary(glm1)

xtabs(~ Fatal + PCF_Violation, data = ml.colsev)
glm2 <- glm(Fatal ~ PCF_Violation, data = ml.colsev, family = "binomial")
summary(glm2)

xtabs(~ Fatal + Light_Condition, data = ml.colsev)
glm3 <- glm(Fatal ~ Light_Condition, data = ml.colsev, family = "binomial")
summary(glm3)

xtabs(~ Fatal + Road_Surface, data = ml.colsev)
glm4 <- glm(Fatal ~ Road_Surface, data = ml.colsev, family = "binomial")
summary(glm4)

xtabs(~ Fatal + Pedestrian_Action, data = ml.colsev)
glm5 <- glm(Fatal ~ Pedestrian_Action, data = ml.colsev, family = "binomial")
summary(glm5)

xtabs(~ Fatal + INTERSECTION, data = ml.colsev)
glm6 <- glm(Fatal ~ INTERSECTION, data = ml.colsev, family = "binomial")
summary(glm6)

xtabs(~ Fatal + Zip, data = ml.colsev)
glm7 <- glm(Fatal ~ Zip, data = ml.colsev, family = "binomial")
summary(glm7)
```

Observing Collision Type

Most of the fatal cases fall under the Vehicle/Pedestrian with 119 incidents. Broadside (side of car) crashes resulted in 30 deaths. All other fatal cases fall below it. This shows that there is a very small sample size to analyze for fatalities.

Based on the coefficients calculated of each feature, 

The standar error of each coefficient are relatively small. Most are less than 1, meaning the estimates are more precise.

However, observing the z-values show that Vehicle/Pedestrian and Sideswipe collision types at -8.838 and 3.265 respectively are sufficiently far from 0, indicating that the estimates are both large and precise enough to be statistically significant.

Finally, we also observe the p-value where lower probabilities provide strong evidence against the null hypothesis. We do this by comparing it to a standard threshold value of 0.05 to begin with. We can determine the following p-values of the explanatory variables below that are less than the threshold value, from most to least significant:

-Vehicle/Pedestrian
-Sideswipe
-Rear End
-Other
-Not Stated 
-Head-On 


We can use this reasoning to apply to all other predictors to determine if they are significiant. We find that Pedestrian Action, Road Surface, Intersection, and Zip are not statistically significant to our model, therefore we can remove them.

---------------

Multiple Explanatory Variables

While there can be a singular predictor to build our model but it is more likely that multiple predictors improve the model. We do have to be careful, however, in inserting too many variables as we may create complicated models and diminish our returns. Instead of building a model for each individual explanatory variable as show below, we can consolidate into one model.

Consolidated into one model

```{r}
glm8 <- glm(Fatal ~ Collision_Type + PCF_Violation + Light_Condition, data = ml.colsev, family = "binomial")
summary(glm8)
```


Although we found significant features within each explanatory variable for both logistic regression models with a single or multiple predictors, a lot of data is lost when consolidating all non-fatal and fatal incidents. We can dive deeper by fine tuning our model to uncover more information on these predictors roles in varying levels of severity in collisions, using our Collision Severity response variable. This is where we use a multinomial logistic regression.






---------------------------
Ignore below

```{r}
install.packages("nnet")
library(nnet)

# mlcolsev <- relevel(mlcolsev["Collision_Severity"], ref = "Injury (Complaint of Pain)")
test <- multinom(Collision_Severity ~ Collision_Type + PCF_Violation + Light_Condition + Road_Surface + Pedestrian_Action, data = ml.colsev)

summary(test)
```



















